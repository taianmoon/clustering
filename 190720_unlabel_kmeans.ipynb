{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149.99773      2.5780058   66.2635     ...   5.077003     0.9692827\n",
      "    1.3175685 ]\n",
      " [150.11905      2.4570513   33.69685    ...   5.012378     2.5274227\n",
      "    4.430969  ]\n",
      " [150.15826      2.139626    65.60122    ...   5.002751     1.2487625\n",
      "    1.8051956 ]\n",
      " ...\n",
      " [150.1225       2.1299489    6.2136927  ...   5.0116863    0.69618124\n",
      "    0.54290056]\n",
      " [150.24413      2.4969258    7.772629   ...   5.0401177    1.1416423\n",
      "    1.1474057 ]\n",
      " [149.93184      2.3198414    7.176956   ...   4.991613     0.737808\n",
      "    0.8937035 ]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1206, 10)\n",
      "[2 2 2 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "#from astropy.table import Table\n",
    "\n",
    "\n",
    "#===========================================Load in data=====================================\n",
    "hdul = fits.open('PCL1002_cat_removeNaN.fits')\n",
    "data = hdul[1].data\n",
    "ra = data.field('ra')\n",
    "dec = data.field('dec')\n",
    "f250 = data.field('f350')\n",
    "et250 = data.field('et250')\n",
    "f350 = data.field('f350')\n",
    "et350 = data.field('et350')\n",
    "f500 = data.field('f500')\n",
    "et500 = data.field('et500')\n",
    "color_f250_f350_pre = data.field('f250/f350')\n",
    "color_f350_f500_pre = data.field('f350/f500')\n",
    "\n",
    "#print(color_f250_f350_pre)\n",
    "#print(type(ra))\n",
    "#print(ra.shape)\n",
    "\n",
    "#color_f250_f350 = []\n",
    "#color_f350_f500 = []\n",
    "#for i in range(0, len(color_f250_f350_pre)):\n",
    "#    if np.isnan(color_f250_f350_pre[i]) == True:\n",
    "#        color_f250_f350.append(0.0)\n",
    "#    elif color_f250_f350_pre[i] == float(\"inf\") or color_f250_f350_pre[i] == float(\"-inf\"):\n",
    "#        color_f250_f350.append(1.0e100)\n",
    "#    else:\n",
    "#        color_f250_f350.append(color_f250_f350_pre[i])\n",
    "#        \n",
    "#for j in range(0, len(color_f350_f500_pre)):\n",
    "#    if np.isnan(color_f350_f500_pre[j]) == True:\n",
    "#        color_f350_f500.append(0.0)\n",
    "#    elif color_f350_f500_pre[i] == float(\"inf\") or color_f350_f500_pre[i] == float(\"-inf\"):\n",
    "#        color_f350_f500.append(1.0e100)\n",
    "#    else:\n",
    "#        color_f350_f500.append(color_f350_f500_pre[j])\n",
    "#\n",
    "#print(color_f250_f350)        \n",
    "#\n",
    "X = np.column_stack((ra, dec, f250, et250, f350, et350, f500, et500, color_f250_f350_pre, color_f350_f500_pre))\n",
    "#X = np.column_stack((ra, dec, f250, et250, f350, et350, f500, et500))\n",
    "#X = np.column_stack((ra, dec, color_f250_f350_pre, color_f350_f500_pre))\n",
    "\n",
    "print(X)\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "#==============================setup classifier=========================================\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X)\n",
    "\n",
    "print(k_means.labels_) #Labels of each point. seq[::n] is a sequence of each n-th item in the entire sequence.\n",
    "\n",
    "np.savetxt('output_kmeans.cat', k_means.labels_, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149.99773      2.5780058   66.2635     ...   5.077003     0.9692827\n",
      "    1.3175685 ]\n",
      " [150.11905      2.4570513   33.69685    ...   5.012378     2.5274227\n",
      "    4.430969  ]\n",
      " [150.15826      2.139626    65.60122    ...   5.002751     1.2487625\n",
      "    1.8051956 ]\n",
      " ...\n",
      " [150.1225       2.1299489    6.2136927  ...   5.0116863    0.69618124\n",
      "    0.54290056]\n",
      " [150.24413      2.4969258    7.772629   ...   5.0401177    1.1416423\n",
      "    1.1474057 ]\n",
      " [149.93184      2.3198414    7.176956   ...   4.991613     0.737808\n",
      "    0.8937035 ]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1206, 10)\n",
      "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False)\n",
      "[3.0220724e+02 1.9985861e+02 1.2352040e+01 5.4193509e-01 2.4583198e-02\n",
      " 1.7281670e-02 1.3899682e-02 4.7092699e-04 8.5868118e-07 2.4558868e-13]\n",
      "(1206, 7)\n"
     ]
    }
   ],
   "source": [
    "#---------------------------PCA---------------------------------\n",
    "from sklearn import cluster\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from sklearn import decomposition\n",
    "\n",
    "#===========================================Load in data=====================================\n",
    "hdul = fits.open('PCL1002_cat_removeNaN.fits')\n",
    "data = hdul[1].data\n",
    "ra = data.field('ra')\n",
    "dec = data.field('dec')\n",
    "f250 = data.field('f350')\n",
    "et250 = data.field('et250')\n",
    "f350 = data.field('f350')\n",
    "et350 = data.field('et350')\n",
    "f500 = data.field('f500')\n",
    "et500 = data.field('et500')\n",
    "color_f250_f350_pre = data.field('f250/f350')\n",
    "color_f350_f500_pre = data.field('f350/f500')\n",
    "\n",
    "X = np.column_stack((ra, dec, f250, et250, f350, et350, f500, et500, color_f250_f350_pre, color_f350_f500_pre))\n",
    "#X = np.column_stack((ra, dec, f250, et250, f350, et350, f500, et500))\n",
    "#X = np.column_stack((ra, dec, color_f250_f350_pre, color_f350_f500_pre))\n",
    "\n",
    "print(X)\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X)\n",
    "print(pca)\n",
    "\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "pca.n_components = 7\n",
    "\n",
    "X_reduced = pca.fit_transform(X) \n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1206, 10)\n",
      "Best parameter (CV score=-66782.352):\n",
      "Pipeline(memory=None,\n",
      "         steps=[('pca',\n",
      "                 PCA(copy=True, iterated_power='auto', n_components=6,\n",
      "                     random_state=None, svd_solver='auto', tol=0.0,\n",
      "                     whiten=False)),\n",
      "                ('k_means',\n",
      "                 KMeans(algorithm='auto', copy_x=True, init='random',\n",
      "                        max_iter=300, n_clusters=5, n_init=10, n_jobs=None,\n",
      "                        precompute_distances='auto', random_state=None,\n",
      "                        tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n",
      "{'k_means__init': 'random', 'k_means__n_clusters': 5, 'pca__n_components': 6}\n",
      "[2 2 2 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#----------------------pipelining--------------------------------------\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import cluster\n",
    "\n",
    "\n",
    "k_means = cluster.KMeans()\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('k_means', k_means)])\n",
    "\n",
    "#===========================================Load in data=====================================\n",
    "hdul = fits.open('PCL1002_cat_removeNaN.fits')\n",
    "data = hdul[1].data\n",
    "ra = data.field('ra')\n",
    "dec = data.field('dec')\n",
    "f250 = data.field('f350')\n",
    "et250 = data.field('et250')\n",
    "f350 = data.field('f350')\n",
    "et350 = data.field('et350')\n",
    "f500 = data.field('f500')\n",
    "et500 = data.field('et500')\n",
    "color_f250_f350_pre = data.field('f250/f350')\n",
    "color_f350_f500_pre = data.field('f350/f500')\n",
    "\n",
    "X = np.column_stack((ra, dec, f250, et250, f350, et350, f500, et500, color_f250_f350_pre, color_f350_f500_pre))\n",
    "#X = np.column_stack((ra, dec, f250, et250, f350, et350, f500, et500))\n",
    "#X = np.column_stack((ra, dec, color_f250_f350_pre, color_f350_f500_pre))\n",
    "\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 6, 7, 8, 9, 10],\n",
    "    'k_means__n_clusters': [2, 3, 4, 5],\n",
    "    'k_means__init': ['k-means++', 'random'],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=5)\n",
    "\n",
    "search.fit(X)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "print(search.best_params_)\n",
    "\n",
    "#print(k_means.labels_) \n",
    "\n",
    "print(search.best_estimator_.named_steps['k_means'].labels_)\n",
    "np.savetxt('output_pca.cat', search.best_estimator_.named_steps['k_means'].labels_, delimiter=' ')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
